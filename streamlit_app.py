import streamlit as st
import sys

# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ
try:
    import google.generativeai as genai
    import docx
except ImportError:
    st.error(
        "å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ï¼š"
    )
    st.code("pip install google-generativeai python-docx")
    st.info(
        "ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ã“ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã€ã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„ã€‚"
    )
    st.stop()

# Streamlitã®UIè¨­å®š
st.title("ğŸ’¬ Chatbotã¨ä»Šæ—¥1æ—¥ã‚’æŒ¯ã‚Šè¿”ã‚ã†ï¼")
st.write(
    "TXTã‚‚ã—ãã¯DOCXå½¢å¼ã®æ—¥è¨˜ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€ãã®å†…å®¹ã«é–¢ã™ã‚‹å¯¾è©±ãŒã§ãã‚‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã™ï¼"
)

# secretsã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã‚€
try:
    gemini_api_key = st.secrets["google_api_key"]
    if not gemini_api_key:
        raise KeyError
except KeyError:
    st.error("APIã‚­ãƒ¼ãŒStreamlitã®secretsã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.info(
        "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«`.streamlit/secrets.toml`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€"
        "ä»¥ä¸‹ã®å½¢å¼ã§APIã‚­ãƒ¼ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚\n\n"
        "```toml\n"
        "google_api_key = \"YOUR_API_KEY_HERE\"\n"
        "```"
        "\n`YOUR_API_KEY_HERE`ã‚’å®Ÿéš›ã®APIã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„ã€‚"
    )
    st.stop()

# Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
genai.configure(api_key=gemini_api_key)
model = genai.GenerativeModel('gemini-2.5-flash-preview-05-20')

# === ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã®è¿½åŠ  ===
uploaded_file = st.file_uploader(
    "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
    type=['txt', 'docx']
)

# === ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…å®¹ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹å¤‰æ•°ã®ä½œæˆ ===
if "messages" not in st.session_state:
    st.session_state.messages = []
if "document_content" not in st.session_state:
    st.session_state.document_content = None

# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹
if uploaded_file is not None:
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€åº¦ã ã‘èª­ã¿è¾¼ã‚€
    if st.session_state.document_content is None:
        try:
            if uploaded_file.type == 'text/plain':
                # .txtãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã€UTF-8ã§ãƒ‡ã‚³ãƒ¼ãƒ‰
                document_content = uploaded_file.getvalue().decode('utf-8')
            elif uploaded_file.type == 'application/vnd.openxmlformats-officedocument.wordprocessingml.document':
                # .docxãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã€python-docxã§èª­ã¿è¾¼ã¿
                document = docx.Document(uploaded_file)
                paragraphs = [p.text for p in document.paragraphs]
                document_content = "\n".join(paragraphs)
            else:
                st.error("ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚")
                st.stop()
            
            st.session_state.document_content = document_content
            st.success("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒæ­£å¸¸ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸã€‚")
            st.session_state.messages = [] # æ–°ã—ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚‰ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆ
            st.info("ã“ã‚Œã§ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å†…å®¹ã«ã¤ã„ã¦è³ªå•ã§ãã¾ã™ã€‚")
            
            # === ã“ã“ã«æœ€åˆã®è³ªå•ã‚’ç”Ÿæˆã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ  ===
            initial_prompt = f"ã“ã‚Œã‹ã‚‰ã‚ãªãŸã®å­¦ç¿’ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚ä»Šæ—¥ã®å­¦ç¿’æ—¥è¨˜ã‚’æ‹è¦‹ã—ã¾ã—ãŸã€‚\n\nãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:\n{document_content}\n\nã¾ãšã¯ã€ã“ã®æ—¥ã®å­¦ç¿’ã§ä¸€ç•ªå°è±¡ã«æ®‹ã£ã¦ã„ã‚‹ã“ã¨ã«ã¤ã„ã¦æ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ"
            
            with st.spinner("æ€è€ƒä¸­ã§ã™..."):
                response = model.generate_content(
                    initial_prompt,
                    stream=False # æœ€åˆã®ä¸€å›ã¯ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§ã¯ãªãã¦ã‚ˆã„
                )
                
            assistant_message = response.text
            st.session_state.messages.append({"role": "assistant", "content": assistant_message})

            st.rerun() # UIã‚’å†æç”»ã—ã¦ãƒãƒ£ãƒƒãƒˆã‚’è¡¨ç¤º

        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# === ãƒãƒ£ãƒƒãƒˆUIã®è¡¨ç¤º ===
if st.session_state.document_content is None:
    st.info("ãƒãƒ£ãƒƒãƒˆã‚’é–‹å§‹ã™ã‚‹ã«ã¯ã€ã¾ãšãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
else:
    # æ—¢å­˜ã®ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®ãƒãƒ£ãƒƒãƒˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    if prompt := st.chat_input("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„"):

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿å­˜ã—ã¦è¡¨ç¤º
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        try:
            # Gemini APIã«æ¸¡ã™ãŸã‚ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ã‚’å¤‰æ›
            history = []
            
            # === ã“ã“ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å†…å®¹ã‚’ã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤ºã¨ã—ã¦æœ€åˆã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ  ===
            document_context = f"ã‚ãªãŸã¯å„ªç§€ãªã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒŠãƒ«ãƒ»ãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼ã§ã‚ã‚Šã€å­¤ç‹¬ã®ä¸­ç‹¬å­¦ã‚’ã™ã‚‹æˆäººå­¦ç¿’è€…ã®è‡ªå·±æˆé•·ã‚’æ”¯æ´ã™ã‚‹ã‚³ãƒ¼ãƒã¨ã—ã¦ã®å½¹å‰²ã‚’æ‹…ã†è¦ªã—ã¿ã‚„ã™ã„ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å­¦ç¿’æ—¥è¨˜ã‚’èª­ã¿ã€å…±æ„Ÿã‚’ç¤ºã—ãªãŒã‚‰ã€ãã®æ—¥ã®å‡ºæ¥äº‹ã‚„æ„Ÿæƒ…ã«ã¤ã„ã¦ã•ã‚‰ã«æ·±ãæ˜ã‚Šä¸‹ã’ã‚‹ã‚ˆã†ãªè³ªå•ã‚’ã—ã¦ãã ã•ã„ã€‚çµè«–ã‚„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æ€¥ãã®ã§ã¯ãªãã€ãƒ¦ãƒ¼ã‚¶ãƒ¼è‡ªèº«ãŒæ°—ã¥ãã‚’å¾—ã‚‰ã‚Œã‚‹ã‚ˆã†ã«å¯¾è©±ã‚’å°ã„ã¦ãã ã•ã„ã€‚\nãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:\n{st.session_state.document_content}"
            history.append({'role': 'user', 'parts': [document_context]})
            
            # === æ—¢å­˜ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚‚è¿½åŠ  ===
            for msg in st.session_state.messages:
                if isinstance(msg, dict) and "role" in msg and "content" in msg:
                    role = "user" if msg["role"] == "user" else "model"
                    history.append({'role': role, 'parts': [msg["content"]]})
            
            # historyãŒç©ºã§ãªã„ã“ã¨ã‚’ç¢ºèª
            if not history:
                st.warning("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãŒç©ºã§ã™ã€‚APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯é€ä¿¡ã•ã‚Œã¾ã›ã‚“ã€‚")
                st.stop()
                
            # Gemini APIã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
            response_stream = model.generate_content(
                history,
                stream=True
            )

            # å¿œç­”ã‚’ãƒãƒ£ãƒƒãƒˆã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºã—ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            full_response = ""
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                for chunk in response_stream:
                    if chunk.parts:
                        text_part = chunk.parts[0].text
                        full_response += text_part
                        message_placeholder.markdown(full_response + "â–Œ")
                message_placeholder.markdown(full_response)
            
            st.session_state.messages.append({"role": "assistant", "content": full_response})

        except Exception as e:
            st.error("ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è©³ç´°ã¯ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            print(f"ã‚¨ãƒ©ãƒ¼ã®è©³ç´°: {e}", file=sys.stderr)
            st.session_state.messages.append({"role": "assistant", "content": "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€å¿œç­”ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"})
