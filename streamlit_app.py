import streamlit as st
import sys

# google-generativeaiãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ
try:
    import google.generativeai as genai
except ImportError:
    st.error(
        "å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ï¼š"
    )
    st.code("pip install google-generativeai")
    st.info(
        "ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ã“ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã€ã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„ã€‚"
    )
    st.stop()

# Streamlitã®UIè¨­å®š
st.title("ğŸ’¬ Chatbot with Gemini Flash 2.5")
st.write(
    "ã“ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¯ã€Googleã®Gemini Flash 2.5ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ "
    "APIã‚­ãƒ¼ã¯Streamlitã®secrets.tomlãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¾ã‚Œã¾ã™ã€‚"
)

# secretsã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã‚€
try:
    gemini_api_key = st.secrets["google_api_key"]
    if not gemini_api_key:
        raise KeyError
except KeyError:
    st.error("APIã‚­ãƒ¼ãŒStreamlitã®secretsã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.info(
        "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«`.streamlit/secrets.toml`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€"
        "ä»¥ä¸‹ã®å½¢å¼ã§APIã‚­ãƒ¼ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚\n\n"
        "```toml\n"
        "google_api_key = \"YOUR_API_KEY_HERE\"\n"
        "```"
        "\n`YOUR_API_KEY_HERE`ã‚’å®Ÿéš›ã®APIã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„ã€‚"
    )
    st.stop()

# Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
genai.configure(api_key=gemini_api_key)
model = genai.GenerativeModel('gemini-2.5-flash-preview-05-20')

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹å¤‰æ•°ã®ä½œæˆ
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ—¢å­˜ã®ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®ãƒãƒ£ãƒƒãƒˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
if prompt := st.chat_input("ä½•ãŒã§ãã¾ã™ã‹ï¼Ÿ"):

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿å­˜ã—ã¦è¡¨ç¤º
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    try:
        # Gemini APIã«æ¸¡ã™ãŸã‚ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ã‚’å¤‰æ›
        history = []
        for msg in st.session_state.messages:
            role = "user" if msg["role"] == "user" else "model"
            history.append({'role': role, 'parts': [msg["content"]]})

        # Gemini APIã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
        response_stream = model.generate_content(
            history,
            stream=True
        )

        # å¿œç­”ã‚’ãƒãƒ£ãƒƒãƒˆã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºã—ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
        full_response = ""
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            for chunk in response_stream:
                if chunk.parts:
                    text_part = chunk.parts[0].text
                    full_response += text_part
                    message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)
        
        st.session_state.messages.append({"role": "assistant", "content": full_response})

    except Exception as e:
        st.error("ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è©³ç´°ã¯ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        print(f"ã‚¨ãƒ©ãƒ¼ã®è©³ç´°: {e}", file=sys.stderr)
        st.session_state.messages.append({"role": "assistant", "content": "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€å¿œç­”ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"})
